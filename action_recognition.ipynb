{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postoperative movement classification of mice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import importlib\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mice_wellbeing import data_handler\n",
    "from mice_wellbeing import model_builder\n",
    "from mice_wellbeing import helper_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload any libraries after change to them without restarting notebook kernel\n",
    "importlib.reload(data_handler)\n",
    "importlib.reload(model_builder)\n",
    "importlib.reload(helper_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lookup for label of each video\n",
    "label_lookup = data_handler.create_label_lookup(path=\"./video/Homecage_Observation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load .csv files with joint coordinates\n",
    "X_pos, X_rel, y = data_handler.load_data_and_labels(datapath=\"/path/to/DLC_project_folder/videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pos[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice data into more but shorter windows\n",
    "X_pos_split, X_rel_split, y_split = data_handler.window_data(X_pos, X_rel, y, num_frames=250, overlap=150, start_buffer=0, end_buffer=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at index 0 for total sample count after slicing\n",
    "X_pos_split.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle slices\n",
    "permutation = np.random.permutation(X_pos_split.shape[0])\n",
    "np.take(X_pos_split, permutation, axis=0, out=X_pos_split)\n",
    "np.take(X_rel_split, permutation, axis=0, out=X_rel_split)\n",
    "np.take(y_split, permutation, axis=0, out=y_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train, val and test\n",
    "train_pct = 0.7\n",
    "val_pct = 0.15\n",
    "# test_pct is the remainder to 1\n",
    "\n",
    "X_pos_train, X_pos_val, X_pos_test = data_handler.np_train_val_test_split(X_pos_split, train_pct=train_pct, val_pct=val_pct, ds_length=X_pos_split.shape[0])\n",
    "X_rel_train, X_rel_val, X_rel_test = data_handler.np_train_val_test_split(X_rel_split, train_pct=train_pct, val_pct=val_pct, ds_length=X_pos_split.shape[0])\n",
    "y_train, y_val, y_test = data_handler.np_train_val_test_split(y_split, train_pct=train_pct, val_pct=val_pct, ds_length=X_pos_split.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for approx. equal distribution of classes in train\n",
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensors for training\n",
    "pos_ds_train =  tf.data.Dataset.from_tensor_slices((X_pos_train.copy(), y_train.copy()), name=\"pos_train\")\n",
    "pos_ds_val =  tf.data.Dataset.from_tensor_slices((X_pos_val.copy(), y_val.copy()), name=\"pos_val\")\n",
    "pos_ds_test =  tf.data.Dataset.from_tensor_slices((X_pos_test.copy(), y_test.copy()), name=\"pos_test\")\n",
    "\n",
    "rel_ds_train =  tf.data.Dataset.from_tensor_slices((X_rel_train.copy(), y_train.copy()), name=\"rel_train\")\n",
    "rel_ds_val =  tf.data.Dataset.from_tensor_slices((X_rel_val.copy(), y_val.copy()), name=\"rel_val\")\n",
    "rel_ds_test =  tf.data.Dataset.from_tensor_slices((X_rel_test.copy(), y_test.copy()), name=\"rel_test\")\n",
    "\n",
    "comb_ds_train = tf.data.Dataset.from_tensor_slices(((X_pos_train.copy(), X_rel_train.copy()), y_train.copy()), name=\"comb_train\")\n",
    "comb_ds_val = tf.data.Dataset.from_tensor_slices(((X_pos_val.copy(), X_rel_val.copy()), y_val.copy()), name=\"comb_val\")\n",
    "comb_ds_test = tf.data.Dataset.from_tensor_slices(((X_pos_test.copy(), X_rel_test.copy()), y_test.copy()), name=\"comb_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle and batch datasets \n",
    "batch_size = 128\n",
    "pos_ds_train = pos_ds_train.shuffle(50000, reshuffle_each_iteration=True).batch(batch_size).shuffle(50000, reshuffle_each_iteration=True)\n",
    "rel_ds_train = rel_ds_train.shuffle(50000, reshuffle_each_iteration=True).batch(batch_size).shuffle(50000, reshuffle_each_iteration=True)\n",
    "comb_ds_train = comb_ds_train.shuffle(50000, reshuffle_each_iteration=True).batch(batch_size).shuffle(50000, reshuffle_each_iteration=True)\n",
    "\n",
    "pos_ds_val = pos_ds_val.batch(batch_size)\n",
    "pos_ds_test = pos_ds_test.batch(batch_size)\n",
    "rel_ds_val = rel_ds_val.batch(batch_size)\n",
    "rel_ds_test = rel_ds_test.batch(batch_size)\n",
    "comb_ds_val = comb_ds_val.batch(batch_size)\n",
    "comb_ds_test = comb_ds_test.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a 2-stream model to use with comb_ds\n",
    "# !overwrites previous models with same var name!\n",
    "# 1-stream model definition below\n",
    "pos_input = keras.Input(X_pos_split.shape[1:], name=\"pos_input\")\n",
    "rel_input = keras.Input(X_rel_split.shape[1:], name=\"rel_input\")\n",
    "\n",
    "# for shared skeleton transformer\n",
    "#-----\n",
    "skeleton_transformer = model_builder.SkeletonTransformerLayerV2((X_pos_split.shape[1:]), name=\"comb_transformer\")\n",
    "\n",
    "pos_x = skeleton_transformer(pos_input)\n",
    "rel_x = skeleton_transformer(rel_input)\n",
    "#-----\n",
    "\n",
    "# for separat skeleton transformers\n",
    "#-----\n",
    "# pos_x = model_builder.SkeletonTransformerLayerV2((X_pos_split.shape[1:]), name=\"pos_transformer\")(pos_input)\n",
    "# rel_x = model_builder.SkeletonTransformerLayerV2((X_pos_split.shape[1:]), name=\"rel_transformer\")(rel_input)\n",
    "#-----\n",
    "\n",
    "pos_x = layers.Conv2D(8, (10, 100), data_format=\"channels_first\", padding=\"same\", name=\"pos_conv\")(pos_x)\n",
    "rel_x = layers.Conv2D(8, (10, 100), data_format=\"channels_first\", padding=\"same\", name=\"rel_conv\")(rel_x)\n",
    "\n",
    "# pooling can be removed here\n",
    "#-----\n",
    "pos_x = layers.MaxPool2D((1, 2), data_format=\"channels_first\", name=\"pos_pooling\")(pos_x)\n",
    "rel_x = layers.MaxPool2D((1, 2), data_format=\"channels_first\", name=\"rel_pooling\")(rel_x)\n",
    "#-----\n",
    "\n",
    "pos_x = keras.Model(inputs=pos_input, outputs=pos_x, name=\"pos_model\")\n",
    "rel_x = keras.Model(inputs=rel_input, outputs=rel_x, name=\"rel_model\")\n",
    "\n",
    "x = layers.concatenate([pos_x.output, rel_x.output], name=\"concat_layer\", axis=1)\n",
    "\n",
    "x = layers.Conv2D(4, (5, 25), data_format=\"channels_first\", padding=\"same\", name=\"comb_conv\")(x)\n",
    "\n",
    "x = layers.Flatten(name=\"flatten_layer\")(x)\n",
    "x = layers.Dense(4, activation=layers.activation.Softmax(), name=\"dense_output\")(x)\n",
    "\n",
    "model = keras.Model(inputs=[pos_input, rel_input], outputs=x, name=\"comb_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a 1-stream model to use with rel_ds or pos_ds\n",
    "# !overwrites previous models with same var name!\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(model_builder.SkeletonTransformerLayerV2((X_pos_split.shape[1:])))\n",
    "\n",
    "model.add(layers.Conv2D(2, (5, 50), data_format=\"channels_first\", padding=\"same\"))\n",
    "\n",
    "model.add(layers.MaxPool2D((1,2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(4, activation=layers.activation.Softmax()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model and set optimizer, loss function and additional metrics\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=[keras.losses.sparse_categorical_crossentropy],\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define early stopping\n",
    "early_stopping_cb =  keras.callbacks.EarlyStopping(monitor='val_loss', patience=100)\n",
    "\n",
    "# define checkpoints\n",
    "checkpoint_filepath = '/home/thomas/bachelorarbeit/models/ckpt/<model_name>_{epoch:02d}-{val_loss:.2f}.keras'\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_loss',\n",
    "    mode='auto',\n",
    "    save_best_only=True,\n",
    "    initial_value_threshold=0.8\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set learning rate\n",
    "K.set_value(model.optimizer.learning_rate, 0.000001) # 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model (change train and val variables depending on model)\n",
    "# comb_ds_train and comb_ds_val for 2-stream\n",
    "# pos_ds_train and pos_ds_val or rel_ds_train and rel_ds_val for 1-stream\n",
    "history = model.fit(pos_ds_train, epochs=10000, callbacks=[early_stopping_cb, model_checkpoint_callback], validation_data=pos_ds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss graph\n",
    "loss_delta = np.array(history.history['loss']) - np.array(history.history['val_loss'])\n",
    "loss_delta = np.abs(loss_delta)\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.plot(loss_delta)\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test', \"delta\"], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy graph\n",
    "accuracy_delta = np.array(history.history[\"accuracy\"]) - np.array(history.history[\"val_accuracy\"])\n",
    "accuracy_delta = np.abs(accuracy_delta)\n",
    "\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.plot(accuracy_delta)\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"test\", \"delta\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation on test data (change var name according to what was used in training)\n",
    "model.evaluate(comb_ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save(\"./models/<model_name>.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save history\n",
    "with open(\"./models/<model_name>.pkl\", \"wb\") as file:\n",
    "    pkl.dump(history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from checkpoint\n",
    "with keras.utils.CustomObjectScope({\"SkeletonTransformerLayerV2\": model_builder.SkeletonTransformerLayerV2}):\n",
    "    loaded_model = keras.models.load_model(\"./models/ckpt/<checkpoint_name>.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model on excluded videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(helper_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from checkpoint\n",
    "with keras.utils.CustomObjectScope({\"SkeletonTransformerLayerV2\": model_builder.SkeletonTransformerLayerV2}):\n",
    "    loaded_model = keras.models.load_model(\"./models/ckpt_new/<model_name>.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply loaded model on excluded videos\n",
    "# set function arguments to reflect process used for data preparation for training\n",
    "result_dict = helper_func.predict_videos(loaded_model, input_mode=\"comb\", num_frames=250, overlap=150, batch_size=128, start_buffer=0, end_buffer=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create additional metrics for excluded videos\n",
    "count_true = 0\n",
    "count_false = 0\n",
    "count_true_weighted = 0\n",
    "count_false_weighted = 0\n",
    "count_true_weighted_p_cutoff = 0\n",
    "count_false_weighted_p_cutoff = 0\n",
    "\n",
    "for vid, pred_dict in result_dict.items():\n",
    "    pred_dict[\"y_guess\"] = pred_dict[\"y_count\"][1].argmax()\n",
    "    pred_dict[\"y_corr\"] = pred_dict[\"y\"] == pred_dict[\"y_guess\"]\n",
    "\n",
    "    pred_dict[\"y_guess_weighted\"] = pred_dict[\"y_pred\"].sum(axis=0) / pred_dict[\"y_pred\"].shape[0]\n",
    "    pred_dict[\"y_corr_weighted\"] = pred_dict[\"y_guess_weighted\"].argmax() == pred_dict[\"y\"]\n",
    "\n",
    "    if pred_dict[\"y_corr\"]:\n",
    "        count_true += 1\n",
    "    else:\n",
    "        count_false += 1\n",
    "    \n",
    "    if pred_dict[\"y_corr_weighted\"]:\n",
    "        count_true_weighted += 1\n",
    "        if np.max(pred_dict[\"y_guess_weighted\"]) >= 0.4:\n",
    "            count_true_weighted_p_cutoff += 1\n",
    "    else:\n",
    "        count_false_weighted += 1\n",
    "        if np.max(pred_dict[\"y_guess_weighted\"]) >= 0.4:\n",
    "            count_false_weighted_p_cutoff += 1\n",
    "\n",
    "    # print(f'{vid=}\\n{pred_dict[\"y\"]=}\\n{pred_dict[\"y_guess\"]=}\\n{pred_dict[\"y_corr\"]=}\\n{pred_dict[\"y_guess_weighted\"]=}\\nCorrect: {pred_dict[\"y_corr_weighted\"]}\\n')\n",
    "\n",
    "print(f\"Argmax accuracy: {count_true / (count_true + count_false)}\\n({count_true=} {count_false=})\")\n",
    "print(f\"Weighted accuracy: {count_true_weighted / (count_true_weighted + count_false_weighted)}\\n({count_true_weighted=} {count_false_weighted=})\")\n",
    "# print(f\"Weighted p cutoff accuracy: {count_true_weighted_p_cutoff / (count_true_weighted_p_cutoff + count_false_weighted_p_cutoff)} on {100 * (count_true_weighted_p_cutoff + count_false_weighted_p_cutoff) / (count_true_weighted + count_false_weighted)}% of Videos\\n({count_true_weighted_p_cutoff=} {count_false_weighted_p_cutoff=})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
